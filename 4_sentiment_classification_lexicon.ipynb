{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from tensorflow.keras.layers import Bidirectional, Dense, Dropout, Embedding, LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11650 entries, 0 to 11649\n",
      "Data columns (total 10 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   ID                   11650 non-null  object\n",
      " 1   Username             11650 non-null  object\n",
      " 2   Comment              11650 non-null  object\n",
      " 3   LikeCount            11650 non-null  int64 \n",
      " 4   ReplyCount           11650 non-null  int64 \n",
      " 5   Date                 11650 non-null  object\n",
      " 6   Comment_clean        11650 non-null  object\n",
      " 7   Comment_clean_words  11504 non-null  object\n",
      " 8   Sentiment_score      11650 non-null  int64 \n",
      " 9   Sentiment            11650 non-null  object\n",
      "dtypes: int64(3), object(7)\n",
      "memory usage: 910.3+ KB\n"
     ]
    }
   ],
   "source": [
    "dir_ = \"dataset/\"\n",
    "file_input = dir_ + \"oshibe_spv_comments_2025-01-15_labeled_lexicon.csv\"\n",
    "data = pd.read_csv(file_input)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Hasil stem dari tahap sebelumnya mengandung missing values pada 'Comment_stem', karena kolom ini akan menjadi X maka row dengan missing values disini akan dihapus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 11504 entries, 0 to 11649\n",
      "Data columns (total 10 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   ID                   11504 non-null  object\n",
      " 1   Username             11504 non-null  object\n",
      " 2   Comment              11504 non-null  object\n",
      " 3   LikeCount            11504 non-null  int64 \n",
      " 4   ReplyCount           11504 non-null  int64 \n",
      " 5   Date                 11504 non-null  object\n",
      " 6   Comment_clean        11504 non-null  object\n",
      " 7   Comment_clean_words  11504 non-null  object\n",
      " 8   Sentiment_score      11504 non-null  int64 \n",
      " 9   Sentiment            11504 non-null  object\n",
      "dtypes: int64(3), object(7)\n",
      "memory usage: 988.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data = data[pd.notnull(data['Comment_clean_words']) & (data['Comment_clean_words'] != '')].copy()\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment_clean_words</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>teman-teman lagu lgbt gadis muda yang beranjak...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>performance videonya kaya memberitahu dampak b...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>persatu member kesempatan menunjukan potensiny...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fiks kedepan jkt48 release single mvnya kostum...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>malam rahasia bilang siapasiapa rahasia ah cah...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>terlepas kontroversi sejujurnya lagu represent...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>terlepas hate comen jujur kemajuan banget jkt4...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gila konsep mv keren banget good job jkt48</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>congrats jkt48 new era mini albumnya jkt48 jay...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>buay yang bilang lesbi salah tuh makna lumayan...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Comment_clean_words Sentiment\n",
       "0  teman-teman lagu lgbt gadis muda yang beranjak...  negative\n",
       "1  performance videonya kaya memberitahu dampak b...  positive\n",
       "2  persatu member kesempatan menunjukan potensiny...  positive\n",
       "3  fiks kedepan jkt48 release single mvnya kostum...  positive\n",
       "4  malam rahasia bilang siapasiapa rahasia ah cah...  negative\n",
       "5  terlepas kontroversi sejujurnya lagu represent...  positive\n",
       "6  terlepas hate comen jujur kemajuan banget jkt4...  positive\n",
       "7         gila konsep mv keren banget good job jkt48  positive\n",
       "8  congrats jkt48 new era mini albumnya jkt48 jay...  positive\n",
       "9  buay yang bilang lesbi salah tuh makna lumayan...  positive"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['Comment_clean_words', 'Sentiment']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define X & y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['Comment_clean_words']\n",
    "y = data['Sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM with TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_svm, X_test_svm, y_train_svm, y_test_svm = train_test_split(X_tfidf, y, test_size=0.2, random_state=48)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with TF-IDF Train Accuracy: 96.82%\n",
      "SVM with TF-IDF Test Accuracy: 91.09%\n",
      "\n",
      "SVM with TF-IDF Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.68      0.79       241\n",
      "     neutral       0.88      0.96      0.92      1195\n",
      "    positive       0.95      0.91      0.93       865\n",
      "\n",
      "    accuracy                           0.91      2301\n",
      "   macro avg       0.92      0.85      0.88      2301\n",
      "weighted avg       0.91      0.91      0.91      2301\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train SVM model\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train_svm, y_train_svm)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_svm_train = svm_model.predict(X_train_svm)\n",
    "y_pred_svm_test = svm_model.predict(X_test_svm)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_svm_train = accuracy_score(y_train_svm, y_pred_svm_train)\n",
    "accuracy_svm_test = accuracy_score(y_test_svm, y_pred_svm_test)\n",
    "\n",
    "print(f\"SVM with TF-IDF Train Accuracy: {accuracy_svm_train*100:.2f}%\")\n",
    "print(f\"SVM with TF-IDF Test Accuracy: {accuracy_svm_test*100:.2f}%\")\n",
    "print()\n",
    "print(\"SVM with TF-IDF Classification Report:\")\n",
    "print(classification_report(y_test_svm, y_pred_svm_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest with TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's just use X_tfidf from above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(X_tfidf, y, test_size=0.2, random_state=48)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with TF-IDF Train Accuracy: 99.97%\n",
      "Random Forest with TF-IDF Test Accuracy: 88.09%\n",
      "\n",
      "Random Forest with TF-IDF Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.60      0.72       241\n",
      "     neutral       0.88      0.92      0.90      1195\n",
      "    positive       0.88      0.91      0.89       865\n",
      "\n",
      "    accuracy                           0.88      2301\n",
      "   macro avg       0.89      0.81      0.84      2301\n",
      "weighted avg       0.88      0.88      0.88      2301\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=48, random_state=48)\n",
    "rf_model.fit(X_train_rf, y_train_rf)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rf_train = rf_model.predict(X_train_rf)\n",
    "y_pred_rf_test = rf_model.predict(X_test_rf)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_rf_train = accuracy_score(y_train_rf, y_pred_rf_train)\n",
    "accuracy_rf_test = accuracy_score(y_test_rf, y_pred_rf_test)\n",
    "\n",
    "print(f\"Random Forest with TF-IDF Train Accuracy: {accuracy_rf_train * 100:.2f}%\")\n",
    "print(f\"Random Forest with TF-IDF Test Accuracy: {accuracy_rf_test * 100:.2f}%\")\n",
    "print()\n",
    "print(\"Random Forest with TF-IDF Classification Report:\")\n",
    "print(classification_report(y_test_rf, y_pred_rf_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest with BoW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Bag of Words (BoW) representation\n",
    "vectorizer = CountVectorizer(max_features=5000)\n",
    "X_bow = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bow, X_test_bow, y_train_bow, y_test_bow = train_test_split(X_bow, y, test_size=0.3, random_state=48)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with Bag of Words Train Accuracy: 99.88%\n",
      "Random Forest with Bag of Words Test Accuracy: 90.09%\n",
      "\n",
      "Random Forest with Bag of Words Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.70      0.77       370\n",
      "     neutral       0.90      0.92      0.91      1737\n",
      "    positive       0.91      0.93      0.92      1345\n",
      "\n",
      "    accuracy                           0.90      3452\n",
      "   macro avg       0.89      0.85      0.87      3452\n",
      "weighted avg       0.90      0.90      0.90      3452\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Random Forest model\n",
    "rf_model_bow = RandomForestClassifier(n_estimators=48, random_state=48)\n",
    "rf_model_bow.fit(X_train_bow, y_train_bow)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_bow_train = rf_model_bow.predict(X_train_bow)\n",
    "y_pred_bow_test = rf_model_bow.predict(X_test_bow)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_bow_train = accuracy_score(y_train_bow, y_pred_bow_train)\n",
    "accuracy_bow_test = accuracy_score(y_test_bow, y_pred_bow_test)\n",
    "\n",
    "print(f\"Random Forest with Bag of Words Train Accuracy: {accuracy_bow_train * 100:.2f}%\")\n",
    "print(f\"Random Forest with Bag of Words Test Accuracy: {accuracy_bow_test * 100:.2f}%\")\n",
    "print()\n",
    "print(\"Random Forest with Bag of Words Classification Report:\")\n",
    "print(classification_report(y_test_bow, y_pred_bow_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['Comment_clean_words'].values\n",
    "y = data['Sentiment'].values\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment_clean_words</th>\n",
       "      <th>Word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9554</th>\n",
       "      <td>malam rahasia bilang siapasiapa rahasia ah cah...</td>\n",
       "      <td>406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>tari perut belly dance dikenal sebutan raqs sh...</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>performance videonya kaya memberitahu dampak b...</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>lyrics japanese naisho konya atta koto dare in...</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3508</th>\n",
       "      <td>resep niku udon ala marugame bahan g udon basa...</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2427</th>\n",
       "      <td>freya</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6633</th>\n",
       "      <td>ngeri</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6638</th>\n",
       "      <td>mantap</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6640</th>\n",
       "      <td>meresahkan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11649</th>\n",
       "      <td>ok</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11504 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Comment_clean_words  Word_count\n",
       "9554   malam rahasia bilang siapasiapa rahasia ah cah...         406\n",
       "256    tari perut belly dance dikenal sebutan raqs sh...         297\n",
       "1      performance videonya kaya memberitahu dampak b...         246\n",
       "729    lyrics japanese naisho konya atta koto dare in...         197\n",
       "3508   resep niku udon ala marugame bahan g udon basa...         185\n",
       "...                                                  ...         ...\n",
       "2427                                               freya           1\n",
       "6633                                               ngeri           1\n",
       "6638                                              mantap           1\n",
       "6640                                          meresahkan           1\n",
       "11649                                                 ok           1\n",
       "\n",
       "[11504 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Word_count'] = data['Comment_clean_words'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "data[['Comment_clean_words', 'Word_count']].sort_values('Word_count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 95th percentile of word count is: 20\n"
     ]
    }
   ],
   "source": [
    "# Calculate the 90th percentile of the word count\n",
    "percentile_95 = np.percentile(data['Word_count'], 95)\n",
    "\n",
    "print(f\"The 95th percentile of word count is: {percentile_95:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "max_words = 10000\n",
    "max_length = int(percentile_95)  # Maximum number of words in a comment\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X)\n",
    "\n",
    "X_seq = tokenizer.texts_to_sequences(X)\n",
    "X_padded = pad_sequences(X_seq, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_padded, y_encoded, test_size=0.2, random_state=48)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 49ms/step - accuracy: 0.6621 - loss: 0.7599 - val_accuracy: 0.8896 - val_loss: 0.3141\n",
      "Epoch 2/5\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 45ms/step - accuracy: 0.9316 - loss: 0.1985 - val_accuracy: 0.8996 - val_loss: 0.2959\n",
      "Epoch 3/5\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - accuracy: 0.9685 - loss: 0.0935 - val_accuracy: 0.9392 - val_loss: 0.2029\n",
      "Epoch 4/5\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - accuracy: 0.9922 - loss: 0.0309 - val_accuracy: 0.9387 - val_loss: 0.2321\n",
      "Epoch 5/5\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 46ms/step - accuracy: 0.9930 - loss: 0.0268 - val_accuracy: 0.9344 - val_loss: 0.2250\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=max_words, output_dim=128),\n",
    "    Bidirectional(LSTM(128, return_sequences=True)),\n",
    "    Dropout(0.2),\n",
    "    Bidirectional(LSTM(64)),\n",
    "    Dropout(0.2),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "Deep Learning Train Accuracy: 99.50%\n",
      "Deep Learning Test Accuracy: 93.44%\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.86      0.88       241\n",
      "     neutral       0.93      0.95      0.94      1195\n",
      "    positive       0.96      0.93      0.94       865\n",
      "\n",
      "    accuracy                           0.93      2301\n",
      "   macro avg       0.93      0.91      0.92      2301\n",
      "weighted avg       0.93      0.93      0.93      2301\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred_test, axis=1)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_dl_train = model.evaluate(X_train, y_train, verbose=0)[1]\n",
    "accuracy_dl_test = model.evaluate(X_test, y_test, verbose=0)[1]\n",
    "print(f\"Deep Learning Train Accuracy: {accuracy_dl_train * 100:.2f}%\")\n",
    "print(f\"Deep Learning Test Accuracy: {accuracy_dl_test * 100:.2f}%\")\n",
    "print()\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_test, y_pred_classes, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Test with Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step\n",
      "New Comment: Marsha muah muah\n",
      "Predicted Sentiment: positive\n",
      "------------------------------\n",
      "New Comment: Aku nggak mau mikir kejauhan, cukup dinikmati aja, kalau nggak suka tinggal skip\n",
      "Predicted Sentiment: neutral\n",
      "------------------------------\n",
      "New Comment: Dih, kok kesel ya liat yang pada komen negatif, kek udah paling bener aja hidupnya\n",
      "Predicted Sentiment: negative\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Create some new comments to predict the sentiment\n",
    "new_comments = [\n",
    "    \"Marsha muah muah\",\n",
    "    \"Aku nggak mau mikir kejauhan, cukup dinikmati aja, kalau nggak suka tinggal skip\",\n",
    "    \"Dih, kok kesel ya liat yang pada komen negatif, kek udah paling bener aja hidupnya\"\n",
    "]\n",
    "\n",
    "# Preprocess the new comments (tokenize and pad)\n",
    "new_sequences = tokenizer.texts_to_sequences(new_comments)\n",
    "new_padded = pad_sequences(new_sequences, maxlen=max_length)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(new_padded)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Decode the predicted classes into sentiment labels\n",
    "predicted_labels = label_encoder.inverse_transform(predicted_classes)\n",
    "\n",
    "# Output results\n",
    "for comment, label in zip(new_comments, predicted_labels):\n",
    "    print(f\"New Comment: {comment}\")\n",
    "    print(f\"Predicted Sentiment: {label}\")\n",
    "    print(\"-\" * 30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
