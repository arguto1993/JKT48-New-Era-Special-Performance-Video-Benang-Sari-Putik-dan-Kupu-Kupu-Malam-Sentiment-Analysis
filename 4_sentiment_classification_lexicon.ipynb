{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from tensorflow.keras.layers import Bidirectional, Dense, Dropout, Embedding, LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11650 entries, 0 to 11649\n",
      "Data columns (total 10 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   ID                   11650 non-null  object\n",
      " 1   Username             11650 non-null  object\n",
      " 2   Comment              11650 non-null  object\n",
      " 3   LikeCount            11650 non-null  int64 \n",
      " 4   ReplyCount           11650 non-null  int64 \n",
      " 5   Date                 11650 non-null  object\n",
      " 6   Comment_clean        11650 non-null  object\n",
      " 7   Comment_clean_words  11504 non-null  object\n",
      " 8   Sentiment_score      11650 non-null  int64 \n",
      " 9   Sentiment            11650 non-null  object\n",
      "dtypes: int64(3), object(7)\n",
      "memory usage: 910.3+ KB\n"
     ]
    }
   ],
   "source": [
    "dir_ = \"dataset/\"\n",
    "file_input = dir_ + \"oshibe_spv_comments_2025-01-15_labeled_lexicon.csv\"\n",
    "data = pd.read_csv(file_input)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Hasil stem dari tahap sebelumnya mengandung missing values pada 'Comment_stem', karena kolom ini akan menjadi X maka row dengan missing values disini akan dihapus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 11504 entries, 0 to 11649\n",
      "Data columns (total 10 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   ID                   11504 non-null  object\n",
      " 1   Username             11504 non-null  object\n",
      " 2   Comment              11504 non-null  object\n",
      " 3   LikeCount            11504 non-null  int64 \n",
      " 4   ReplyCount           11504 non-null  int64 \n",
      " 5   Date                 11504 non-null  object\n",
      " 6   Comment_clean        11504 non-null  object\n",
      " 7   Comment_clean_words  11504 non-null  object\n",
      " 8   Sentiment_score      11504 non-null  int64 \n",
      " 9   Sentiment            11504 non-null  object\n",
      "dtypes: int64(3), object(7)\n",
      "memory usage: 988.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data = data[pd.notnull(data['Comment_clean_words']) & (data['Comment_clean_words'] != '')].copy()\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment_clean_words</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>teman-teman lagu lgbt gadis muda yang beranjak...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>performance videonya kaya memberitahu dampak b...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>persatu member kesempatan menunjukan potensiny...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fiks kedepan jkt48 release single mvnya kostum...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>malam rahasia bilang siapasiapa rahasia ah cah...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>terlepas kontroversi sejujurnya lagu represent...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>terlepas hate comen jujur kemajuan banget jkt4...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gila konsep mv keren banget good job jkt48</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>congrats jkt48 new era mini albumnya jkt48 jay...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>buay yang bilang lesbi salah tuh makna lumayan...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Comment_clean_words Sentiment\n",
       "0  teman-teman lagu lgbt gadis muda yang beranjak...  negative\n",
       "1  performance videonya kaya memberitahu dampak b...  positive\n",
       "2  persatu member kesempatan menunjukan potensiny...  positive\n",
       "3  fiks kedepan jkt48 release single mvnya kostum...  positive\n",
       "4  malam rahasia bilang siapasiapa rahasia ah cah...  negative\n",
       "5  terlepas kontroversi sejujurnya lagu represent...  positive\n",
       "6  terlepas hate comen jujur kemajuan banget jkt4...  positive\n",
       "7         gila konsep mv keren banget good job jkt48  positive\n",
       "8  congrats jkt48 new era mini albumnya jkt48 jay...  positive\n",
       "9  buay yang bilang lesbi salah tuh makna lumayan...  positive"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['Comment_clean_words', 'Sentiment']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define X & y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['Comment_clean_words']\n",
    "y = data['Sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM with TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_svm, X_test_svm, y_train_svm, y_test_svm = train_test_split(X_tfidf, y, test_size=0.2, random_state=48)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with TF-IDF Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.68      0.79       241\n",
      "     neutral       0.88      0.96      0.92      1195\n",
      "    positive       0.95      0.91      0.93       865\n",
      "\n",
      "    accuracy                           0.91      2301\n",
      "   macro avg       0.92      0.85      0.88      2301\n",
      "weighted avg       0.91      0.91      0.91      2301\n",
      "\n",
      "SVM with TF-IDF Train Accuracy: 96.82%\n",
      "SVM with TF-IDF Test Accuracy: 91.09%\n"
     ]
    }
   ],
   "source": [
    "# Train SVM model\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train_svm, y_train_svm)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_svm_train = svm_model.predict(X_train_svm)\n",
    "y_pred_svm_test = svm_model.predict(X_test_svm)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_svm_train = accuracy_score(y_train_svm, y_pred_svm_train)\n",
    "accuracy_svm_test = accuracy_score(y_test_svm, y_pred_svm_test)\n",
    "\n",
    "print(\"SVM with TF-IDF Classification Report:\")\n",
    "print(classification_report(y_test_svm, y_pred_svm_test))\n",
    "\n",
    "print(f\"SVM with TF-IDF Train Accuracy: {accuracy_svm_train*100:.2f}%\")\n",
    "print(f\"SVM with TF-IDF Test Accuracy: {accuracy_svm_test*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest with BoW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique words: 11536\n",
      "Using 50% of unique words: 5768 features\n"
     ]
    }
   ],
   "source": [
    "# Initialize CountVectorizer without limiting features\n",
    "vectorizer = CountVectorizer()\n",
    "X_bow = vectorizer.fit_transform(X)\n",
    "\n",
    "# Get the number of unique words\n",
    "total_unique_words = len(vectorizer.get_feature_names_out())\n",
    "print(f\"Total unique words: {total_unique_words}\")\n",
    "\n",
    "# Define percentage of unique words to include\n",
    "percentage = 0.5  # Example: use 50% of the unique words\n",
    "max_features = int(total_unique_words * percentage)\n",
    "\n",
    "print(f\"Using {percentage * 100:.0f}% of unique words: {max_features} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Bag of Words (BoW) representation\n",
    "vectorizer = CountVectorizer(max_features=max_features)\n",
    "X_bow = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bow, X_test_bow, y_train_bow, y_test_bow = train_test_split(X_bow, y, test_size=0.3, random_state=48)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with Bag of Words Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.69      0.76       370\n",
      "     neutral       0.90      0.92      0.91      1737\n",
      "    positive       0.90      0.93      0.92      1345\n",
      "\n",
      "    accuracy                           0.90      3452\n",
      "   macro avg       0.88      0.84      0.86      3452\n",
      "weighted avg       0.90      0.90      0.89      3452\n",
      "\n",
      "Random Forest with Bag of Words Train Accuracy: 99.89%\n",
      "Random Forest with Bag of Words Test Accuracy: 89.63%\n"
     ]
    }
   ],
   "source": [
    "# Train Random Forest model\n",
    "rf_model_bow = RandomForestClassifier(n_estimators=48, random_state=48)\n",
    "rf_model_bow.fit(X_train_bow, y_train_bow)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_bow_train = rf_model_bow.predict(X_train_bow)\n",
    "y_pred_bow_test = rf_model_bow.predict(X_test_bow)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_bow_train = accuracy_score(y_train_bow, y_pred_bow_train)\n",
    "accuracy_bow_test = accuracy_score(y_test_bow, y_pred_bow_test)\n",
    "\n",
    "print(\"Random Forest with Bag of Words Classification Report:\")\n",
    "print(classification_report(y_test_bow, y_pred_bow_test))\n",
    "\n",
    "print(f\"Random Forest with Bag of Words Train Accuracy: {accuracy_bow_train * 100:.2f}%\")\n",
    "print(f\"Random Forest with Bag of Words Test Accuracy: {accuracy_bow_test * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['Comment_clean_words'].values\n",
    "y = data['Sentiment'].values\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment_clean_words</th>\n",
       "      <th>Word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9554</th>\n",
       "      <td>malam rahasia bilang siapasiapa rahasia ah cah...</td>\n",
       "      <td>406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>tari perut belly dance dikenal sebutan raqs sh...</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>performance videonya kaya memberitahu dampak b...</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>lyrics japanese naisho konya atta koto dare in...</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3508</th>\n",
       "      <td>resep niku udon ala marugame bahan g udon basa...</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2427</th>\n",
       "      <td>freya</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6633</th>\n",
       "      <td>ngeri</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6638</th>\n",
       "      <td>mantap</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6640</th>\n",
       "      <td>meresahkan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11649</th>\n",
       "      <td>ok</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11504 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Comment_clean_words  Word_count\n",
       "9554   malam rahasia bilang siapasiapa rahasia ah cah...         406\n",
       "256    tari perut belly dance dikenal sebutan raqs sh...         297\n",
       "1      performance videonya kaya memberitahu dampak b...         246\n",
       "729    lyrics japanese naisho konya atta koto dare in...         197\n",
       "3508   resep niku udon ala marugame bahan g udon basa...         185\n",
       "...                                                  ...         ...\n",
       "2427                                               freya           1\n",
       "6633                                               ngeri           1\n",
       "6638                                              mantap           1\n",
       "6640                                          meresahkan           1\n",
       "11649                                                 ok           1\n",
       "\n",
       "[11504 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Word_count'] = data['Comment_clean_words'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "data[['Comment_clean_words', 'Word_count']].sort_values('Word_count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 95th percentile of word count is: 20\n"
     ]
    }
   ],
   "source": [
    "# Calculate the 90th percentile of the word count\n",
    "percentile_95 = np.percentile(data['Word_count'], 95)\n",
    "\n",
    "print(f\"The 95th percentile of word count is: {percentile_95:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "max_words = 10000\n",
    "max_length = int(percentile_95)  # Maximum number of words in a comment\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X)\n",
    "\n",
    "X_seq = tokenizer.texts_to_sequences(X)\n",
    "X_padded = pad_sequences(X_seq, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_padded, y_encoded, test_size=0.2, random_state=48)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 52ms/step - accuracy: 0.6780 - loss: 0.7414 - val_accuracy: 0.8848 - val_loss: 0.3203\n",
      "Epoch 2/5\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 64ms/step - accuracy: 0.9351 - loss: 0.2041 - val_accuracy: 0.9144 - val_loss: 0.2358\n",
      "Epoch 3/5\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 50ms/step - accuracy: 0.9787 - loss: 0.0733 - val_accuracy: 0.9148 - val_loss: 0.2808\n",
      "Epoch 4/5\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 51ms/step - accuracy: 0.9845 - loss: 0.0442 - val_accuracy: 0.9322 - val_loss: 0.2300\n",
      "Epoch 5/5\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 51ms/step - accuracy: 0.9941 - loss: 0.0224 - val_accuracy: 0.9352 - val_loss: 0.2718\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=max_words, output_dim=128),\n",
    "    Bidirectional(LSTM(128, return_sequences=True)),\n",
    "    Dropout(0.2),\n",
    "    Bidirectional(LSTM(64)),\n",
    "    Dropout(0.2),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.80      0.87       241\n",
      "     neutral       0.93      0.95      0.94      1195\n",
      "    positive       0.95      0.95      0.95       865\n",
      "\n",
      "    accuracy                           0.94      2301\n",
      "   macro avg       0.94      0.90      0.92      2301\n",
      "weighted avg       0.94      0.94      0.93      2301\n",
      "\n",
      "Deep Learning Accuracy: 93.52%\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_test, y_pred_classes, target_names=label_encoder.classes_))\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_dl = model.evaluate(X_test, y_test, verbose=0)[1]\n",
    "print(f\"Deep Learning Accuracy: {accuracy_dl * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Test with Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
