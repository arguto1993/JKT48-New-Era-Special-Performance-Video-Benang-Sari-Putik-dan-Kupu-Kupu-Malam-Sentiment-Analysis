{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from tensorflow.keras.layers import Bidirectional, Dense, Dropout, LSTM, Embedding\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11650 entries, 0 to 11649\n",
      "Data columns (total 11 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   ID             11650 non-null  object \n",
      " 1   Username       11650 non-null  object \n",
      " 2   Comment        11650 non-null  object \n",
      " 3   LikeCount      11650 non-null  int64  \n",
      " 4   ReplyCount     11650 non-null  int64  \n",
      " 5   Date           11650 non-null  object \n",
      " 6   Comment_clean  11650 non-null  object \n",
      " 7   Comment_size   11650 non-null  int64  \n",
      " 8   Sentiment      11650 non-null  object \n",
      " 9   Confidence     11650 non-null  float64\n",
      " 10  Comment_stem   11339 non-null  object \n",
      "dtypes: float64(1), int64(3), object(7)\n",
      "memory usage: 1001.3+ KB\n"
     ]
    }
   ],
   "source": [
    "dir_ = \"dataset/\"\n",
    "file_input = dir_ + \"oshibe_spv_comments_2025-01-15_labeled_stem.csv\"\n",
    "data = pd.read_csv(file_input)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Hasil stem dari tahap sebelumnya mengandung missing values pada 'Comment_stem', karena kolom ini akan menjadi X maka row dengan missing values disini akan dihapus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 11339 entries, 0 to 11649\n",
      "Data columns (total 11 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   ID             11339 non-null  object \n",
      " 1   Username       11339 non-null  object \n",
      " 2   Comment        11339 non-null  object \n",
      " 3   LikeCount      11339 non-null  int64  \n",
      " 4   ReplyCount     11339 non-null  int64  \n",
      " 5   Date           11339 non-null  object \n",
      " 6   Comment_clean  11339 non-null  object \n",
      " 7   Comment_size   11339 non-null  int64  \n",
      " 8   Sentiment      11339 non-null  object \n",
      " 9   Confidence     11339 non-null  float64\n",
      " 10  Comment_stem   11339 non-null  object \n",
      "dtypes: float64(1), int64(3), object(7)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "data = data[pd.notnull(data['Comment_stem']) & (data['Comment_stem'] != '')]\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment_stem</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lagu gadis muda yg anjak dewasa hilang polos p...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>performance video kaya memberitahu dampak buru...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>satu member sempat tunjuk biar gk iri wotanya ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>depan jkt48 release single mvnya gak konsep ce...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>malam rahasia ya bilang rahasia cahaya awan hi...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lepas kontroversi jujur lagu representasi real...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lepas hate comen jujur maju banget konsep nger...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gila konsep mv nya keren good job jkt48</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>congrats jkt48 new era mini jkt48 jaya jaya jaya</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>buay yg blg lesbi salah tuh makna lumayan bera...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Comment_stem Sentiment\n",
       "0  lagu gadis muda yg anjak dewasa hilang polos p...   neutral\n",
       "1  performance video kaya memberitahu dampak buru...   neutral\n",
       "2  satu member sempat tunjuk biar gk iri wotanya ...  positive\n",
       "3  depan jkt48 release single mvnya gak konsep ce...  positive\n",
       "4  malam rahasia ya bilang rahasia cahaya awan hi...   neutral\n",
       "5  lepas kontroversi jujur lagu representasi real...   neutral\n",
       "6  lepas hate comen jujur maju banget konsep nger...  positive\n",
       "7            gila konsep mv nya keren good job jkt48  positive\n",
       "8   congrats jkt48 new era mini jkt48 jaya jaya jaya  positive\n",
       "9  buay yg blg lesbi salah tuh makna lumayan bera...  positive"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['Comment_stem', 'Sentiment']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define X & y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['Comment_stem']\n",
    "y = data['Sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM with TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=48)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with TF-IDF Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.66      0.69       745\n",
      "     neutral       0.63      0.54      0.58       455\n",
      "    positive       0.75      0.83      0.79      1068\n",
      "\n",
      "    accuracy                           0.72      2268\n",
      "   macro avg       0.70      0.68      0.69      2268\n",
      "weighted avg       0.71      0.72      0.71      2268\n",
      "\n",
      "SVM with TF-IDF Accuracy: 0.718694885361552\n"
     ]
    }
   ],
   "source": [
    "# Train SVM model\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"SVM with TF-IDF Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"SVM with TF-IDF Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest with Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the comments\n",
    "tokenized_comments = [comment.split() for comment in X]\n",
    "\n",
    "# Train Word2Vec model\n",
    "word2vec_model = Word2Vec(sentences=tokenized_comments, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Create feature vectors for each comment by averaging word vectors\n",
    "def get_vector(comment):\n",
    "    words = comment.split()\n",
    "    word_vecs = [word2vec_model.wv[word] for word in words if word in word2vec_model.wv]\n",
    "    return np.mean(word_vecs, axis=0) if word_vecs else np.zeros(word2vec_model.vector_size)\n",
    "\n",
    "X_word2vec = np.array([get_vector(comment) for comment in X])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_w2v, X_test_w2v, y_train_w2v, y_test_w2v = train_test_split(X_word2vec, y, test_size=0.2, random_state=48)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with Word2Vec Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.60      0.55      0.57       745\n",
      "     neutral       0.58      0.39      0.46       455\n",
      "    positive       0.66      0.79      0.72      1068\n",
      "\n",
      "    accuracy                           0.63      2268\n",
      "   macro avg       0.61      0.58      0.59      2268\n",
      "weighted avg       0.62      0.63      0.62      2268\n",
      "\n",
      "Random Forest with Word2Vec Accuracy: 0.6305114638447972\n"
     ]
    }
   ],
   "source": [
    "# Train Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=150)\n",
    "rf_model.fit(X_train_w2v, y_train_w2v)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_w2v = rf_model.predict(X_test_w2v)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Random Forest with Word2Vec Classification Report:\")\n",
    "print(classification_report(y_test_w2v, y_pred_w2v))\n",
    "print(\"Random Forest with Word2Vec Accuracy:\", accuracy_score(y_test_w2v, y_pred_w2v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['Comment_stem'].values\n",
    "y = data['Sentiment'].values\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "max_words = 10000\n",
    "max_length = 100  # Maximum number of words in a comment\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X)\n",
    "\n",
    "X_seq = tokenizer.texts_to_sequences(X)\n",
    "X_padded = pad_sequences(X_seq, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_padded, y_encoded, test_size=0.2, random_state=48)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\DOCUMENTS\\ARGUTO THE ANALYST\\Portfolio\\JKT48 Oshibe Sentiment\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 176ms/step - accuracy: 0.5488 - loss: 0.9317 - val_accuracy: 0.6781 - val_loss: 0.7128\n",
      "Epoch 2/10\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 187ms/step - accuracy: 0.8024 - loss: 0.5186 - val_accuracy: 0.6861 - val_loss: 0.7393\n",
      "Epoch 3/10\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 195ms/step - accuracy: 0.8832 - loss: 0.3364 - val_accuracy: 0.7015 - val_loss: 0.7680\n",
      "Epoch 4/10\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 186ms/step - accuracy: 0.9138 - loss: 0.2551 - val_accuracy: 0.7130 - val_loss: 0.8774\n",
      "Epoch 5/10\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 187ms/step - accuracy: 0.9371 - loss: 0.1911 - val_accuracy: 0.7103 - val_loss: 0.9086\n",
      "Epoch 6/10\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 180ms/step - accuracy: 0.9460 - loss: 0.1619 - val_accuracy: 0.7094 - val_loss: 0.9706\n",
      "Epoch 7/10\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 187ms/step - accuracy: 0.9514 - loss: 0.1419 - val_accuracy: 0.7037 - val_loss: 1.0581\n",
      "Epoch 8/10\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 182ms/step - accuracy: 0.9523 - loss: 0.1329 - val_accuracy: 0.7086 - val_loss: 1.1722\n",
      "Epoch 9/10\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 183ms/step - accuracy: 0.9571 - loss: 0.1169 - val_accuracy: 0.6980 - val_loss: 1.1870\n",
      "Epoch 10/10\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 184ms/step - accuracy: 0.9618 - loss: 0.1034 - val_accuracy: 0.7086 - val_loss: 1.2913\n"
     ]
    }
   ],
   "source": [
    "# Define the model with more layers\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=max_words, output_dim=128, input_length=max_length),\n",
    "    Bidirectional(LSTM(128, return_sequences=True)),\n",
    "    Dropout(0.2),\n",
    "    Bidirectional(LSTM(64)),\n",
    "    Dropout(0.2),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.65      0.66       713\n",
      "     neutral       0.67      0.54      0.60       467\n",
      "    positive       0.75      0.82      0.78      1088\n",
      "\n",
      "    accuracy                           0.71      2268\n",
      "   macro avg       0.69      0.67      0.68      2268\n",
      "weighted avg       0.70      0.71      0.70      2268\n",
      "\n",
      "Deep Learning Accuracy: 70.86%\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_test, y_pred_classes, target_names=label_encoder.classes_))\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_dl = model.evaluate(X_test, y_test, verbose=0)[1]\n",
    "print(f\"Deep Learning Accuracy: {accuracy_dl * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
